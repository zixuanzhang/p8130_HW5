---
title: "p8130 Homework 5"
author: "Eleanor Zhang uni: zz2602"
date: "12/1/2018"
geometry: margin=2cm
output: 
     pdf_document:
         latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library("caret", "boot", "MPV")
library(modelr)
```


## Read Data

R dataset ‘state.x77’ from library(faraway) contains information on 50 states from 1970s collected by US Census Bureau. The goal is to predict ‘life expectancy’ using a combination of remaining variables.

Here the main response is life expectancy. The rest variables constitute the pool of variables that may be selected for regression model.

```{r message=FALSE, warning=FALSE}
library(faraway)
data(state)
state <- as.tibble(state.x77) %>% 
  janitor::clean_names() # clean variable names
```

## Explore the data

#### data description
```{r}
str(state) # 50 rows, 8 variables
```

The dataset contains 50 observations and 8 variables

Data description:  

*  population: population estimate as of July 1, 1975
*  income: per capita income (1974)
*  illiteracy: illiteracy (1970, percent of population)
*  life_exp (main response): life expectancy in years (1969–71)
*  murder: murder and non-negligent manslaughter rate per 100,000 population (1976)
*  hs_grad: percent high-school graduates (1970)
*  frost: mean number of days with minimum temperature below freezing (1931–1960) in capital or large city
*  area: land area in square miles

#### Problem 1 Explore the data and summary

Number summary

```{r summary}
summary(state) 
anyNA(state) # NO missing value
```

Display distributin of variables in order described above 

```{r histogram}
par(mfrow = c(2,4))
hist(state$population, main = "population")
hist(state$income, main = "income")
hist(state$illiteracy, main = "illitarcy")
hist(state$life_exp, main = "life_exp")
hist(state$murder, main = "murder")
hist(state$hs_grad, main = "hs_grad")
hist(state$frost, main = "frost")
hist(state$area, main = "area")
```

__Observe__:  

*  skewed: population size, illteracy, area (reported by median and IQR)
*  the other distribution looks evenly shaped (reported by mean and sd)

relationship between covariates

```{r correlation}
state %>% select(life_exp, everything()) %>% pairs()
cor(state) %>% knitr::kable()
```

__Observe__:

*  murder and illiteracy seems to have exponential relation
*  Area may need to be categorized
*  life expectancy are negatively and linearly associated with murder rate and illiteracy repectively. There is some positive linear relation between life expectancy and high school graduates percentage and frost days.
*  Some potential colinearity: hs_grad and income, hs_grad and illiteracy, 

#### Problem 2 Automatic procedure

```{r fit with all predictors}
multi.fit <- lm(life_exp ~ ., data = state)
summary(multi.fit)
```

__Comment__: murder is the most significant predictor. hs_grad is significant at 0.05 level. The other predictors are not very significant when including all other variables in the model. The adjusted R-square is penalized such that it is significantly smaller than the unadjusted one. This implies we have included unnecessary predictors in the model.

1) __Method I: Backward elimination (choose alpha_to_remove > 0.2)__

Start from there, we use backward elimination to find the "best" subset:

By looking at the summary of full model regression, backward elimination starts eliminating the one with largest p value, so we __remove area__ first

```{r remove area}
step1 <- update(multi.fit, . ~ . -area)
summary(step1)
```

Then we __remove illiteracy__

```{r remove illiteracy}
step2 <- update(step1, . ~ . -illiteracy)
summary(step2)
```

Then we __remove income__

```{r}
step3 <- update(step2, . ~ . -income)
summary(step3)
```

As we set alpha_to_remove = 0.2 at the beginning. There is no further reduction of variable at the stage. 

Result: backward selection model is 

life expectancy = 71 + 0.00005population - 0.3Murder + 0.047hs_grad - 0.006frost


2) __Method II: Forward elimination (choose alpha to enter < 0.2)__

We begin with regression with ech single predictor and obtain their summaries

```{r}
fit_pop <- lm(life_exp ~ population, data = state)
result <- tibble(model = map(state[-4], ~lm(life_exp ~ .x, data = state))) %>% 
  mutate(result = map(model, broom::tidy)) %>% 
  select(-model) %>% 
  unnest() %>% 
  filter(term == ".x") %>% 
  select(-statistic) %>% 
  mutate(term = c("population", "income", "illiteracy", "murder", "hs_grad", "frost", "area"),
         estimate = round(estimate, digits = 6),
         std.error = round(std.error, digits = 6))
result %>% arrange(p.value) # rank by p value
```

Enter variable with smallest p value: murder

```{r}
library(broom)
forward1 <- lm(life_exp ~ murder, data = state)
```

Enter variable with the smallest p value among the rest: 

```{r}
fit1 <- update(forward1, . ~ . +population)
fit2 <- update(forward1, . ~ . +income)
fit3 <- update(forward1, . ~ . +illiteracy)
fit4 <- update(forward1, . ~ . +hs_grad)
fit5 <- update(forward1, . ~ . +frost)
fit6 <- update(forward1, . ~ . +area)

result2 <- tibble(model = map(list(fit1, fit2, fit3, fit4, fit5, fit6), summary)) %>% 
  mutate(result = map(model, tidy)) %>% 
  select(-model) %>% 
  unnest(result)

result2 %>% 
  filter(!term %in% c("(Intercept)", "murder")) %>% 
  mutate(rank_p_value = rank(p.value)) %>% 
  right_join(., result2)
```

Enter variable: hs_grad

```{r}
forward2 <- lm(life_exp ~ murder + hs_grad, data = state)
tidy(forward2)
```

Enter variable with the smallest p value among the rest: 

```{r}
fit1 <- update(forward2, . ~ . +population)
fit2 <- update(forward2, . ~ . +income)
fit3 <- update(forward2, . ~ . +illiteracy)
fit4 <- update(forward2, . ~ . +frost)
fit5 <- update(forward2, . ~ . +area)

result3 <- tibble(model = map(list(fit1, fit2, fit3, fit4, fit5), summary)) %>% 
  mutate(result = map(model, tidy)) %>% 
  select(-model) %>% 
  unnest(result)

result3 %>% 
  filter(!term %in% c("(Intercept)", "murder", "hs_grad")) %>% 
  mutate(rank_p_value = rank(p.value)) %>% 
  right_join(., result3)
```

Enter: frost

```{r}
forward3 <- lm(life_exp ~ murder + hs_grad + frost, data = state)
summary(forward3)
```

Enter variable with the smallest p value among the rest: 

```{r}
fit1 <- update(forward3, . ~ . +population)
fit2 <- update(forward3, . ~ . +income)
fit3 <- update(forward3, . ~ . +illiteracy)
fit4 <- update(forward3, . ~ . +area)

result4 <- tibble(model = map(list(fit1, fit2, fit3, fit4), summary)) %>% 
  mutate(result = map(model, tidy)) %>% 
  select(-model) %>% 
  unnest(result)

result4 %>% 
  filter(!term %in% c("(Intercept)", "murder", "hs_grad", "frost")) %>% 
  mutate(rank_p_value = rank(p.value)) %>% 
  right_join(., result4)
```

Add population

```{r}
forward4 <- lm(life_exp ~ murder + hs_grad + frost + population, data = state)
summary(forward4)
```

Enter variable with the smallest p value among the rest: 

```{r}
fit1 <- update(forward4, . ~ . +income)
fit2 <- update(forward4, . ~ . +illiteracy)
fit3 <- update(forward4, . ~ . +area)

result5 <- tibble(model = map(list(fit1, fit2, fit3), summary)) %>% 
  mutate(result = map(model, tidy)) %>% 
  select(-model) %>% 
  unnest(result)

result5 %>% 
  filter(!term %in% c("(Intercept)", "murder", "hs_grad", "frost", "population")) %>% 
  mutate(rank_p_value = rank(p.value)) %>% 
  right_join(., result5)
```

There is no additional predictor with p < 0.2, so we will not enter any other predictor. Hence, the forward selection model:

life_exp ~ 71 - 0.3murder + 0.047hs_grad - 0.006frost + 0.00005population


__Method III: stepwise regression__

```{r}
mult.fit <- lm(life_exp ~ ., data = state)
step(mult.fit, direction = 'both') # select by AIC 
```

We choose the one with smallest AIC, hence the model selected by stepwise regression procedure is:  

life_exp = 71 + 0.00005population - 0.3murder + 0.047hs_grad - 0.006frost


__Answer questions__:

a) All the three procedures end up with the same model: life_exp ~ population + murder + hs_grad + frost.

b) During the forward and backward elimination procedures, the variable population is close to the not rejection region in terms of p value if we choose alpha to be 0.05. However, at this stage of exploratory analysis, we want to leverage the critical alpha value to be more inclusive and less stringent in variable selection. Therefore we keep this variable "population" in the model.

c) illteracy vs. HS graduation rate

```{r}
cor(state$illiteracy, state$hs_grad)
```

The linear correlation between illeteracy and HS graduation rate is -0.66. This makes sense because lower high graduation rate can be associated with higher rate of illiteracy. The subsets in the above do not contain both variable. 


### Problem 3 Criterion based procedure

We used criterion of Cp and adjusted R square to select for the best model

```{r function of best model}
library(leaps)
best <- function(model, ...) 
{
  subsets <- regsubsets(formula(model), model.frame(model), ...)
  subsets <- with(summary(subsets),
                  cbind(p = as.numeric(rownames(which)), which, rss, rsq, adjr2, cp, bic))
  
  return(subsets)
} 
```

```{r}
best_result <- round(best(multi.fit), 4) %>% as.tibble()
best_result %>% knitr::kable()

par(mar=c(4,4,1,1))
par(mfrow=c(1,2))


plot(2:8, best_result$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1) 

plot(2:8, best_result$adjr2, xlab="No of parameters", ylab="Adj R2")
```


__Comment__: From the criterion of Cp and Adjusted R square, 5 parameters reach to the summit of adjusted R square with Cp smaller than number of parameters. So we decide to choose the model with 5 parameter (4 predictors):  life_exp ~ population + murder + hs_grad + frost. The model we achieved here is consistent with the automatic procedure result above.

### Problem 4 choose final model and checking assumption

Given the automatic procedure and criterion based procedure arrive at the same model, we will recommend this consistent result as our final model with 4 predictors: life_exp ~ population + murder + hs_grad + frost

```{r final model}
multi.fit4 <- lm(life_exp ~ population + murder + hs_grad + frost, data = state)
summary(multi.fit4)
```


a) Identify leverage and/or influential points

1. check outliers in outcome (life_exp)

```{r outlier in y}
stu_res <- rstandard(multi.fit4) # calculate studentized residuals
outliers_y <- stu_res[abs(stu_res)>2.5]
outliers_y
```

__Comment__: we did not find any outlier in life expectancy (response)

2. check leverage and infulential points 

Some influential points can be identified on diagnostic plot:

```{r}
par(mfrow = c(2,2))
plot(multi.fit4)
```

Numerical measure of influential points:

```{r}
influ.point <- influence.measures(multi.fit4)
summary(influ.point) %>% knitr::kable()
```

__Comment__: obseravtion 5 is an influential point in terms of predictor with high leverage value. observation 11 is identified with high DFFITS value so it affects the observation 11 fitted value. On the diagnostic plot, case 11 appears problematic on each plot. Therefore, we remove this point and do analysis again.

b) check model assumption

From previous conclusion, here we remove the observation 11 and compare the residuals plots with previous ones. 

```{r}
state_no_11 <- state[-11,]
multi.fit4.no11 <- lm(life_exp ~ population + murder + hs_grad + frost, data = state_no_11)
par(mfrow = c(2,2))
plot(multi.fit4.no11)
```

__Comment__: After removing the influential point observation 11, we observed the residuals variances are stabilized and normality is improved as well. So we will continue the following analysis based on the dataset without observation 11.

### Problem 5

__a) 10 fold cross validation__

Final Model: life_exp ~ population + murder + hs_grad + frost

```{r create data train}
data_train <- trainControl(method="cv", number=10)
```

Fit for 4 predictor model

```{r}
model_caret <- train(life_exp ~ population + murder + hs_grad + frost,
                   data = state_no_11,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
model_caret
sd(model_caret$resample$Rsquared) # training data R2
```

__Comment__: the RMSE is 0.695 over the 10 folds of testing data. R square is 0.8. The R square shows that 80% the variation in life expectancy can be explained by these four predictors. 


__b) A new bootstrap : residual sampling__

i) fit model with full dataset, get predicted value and resididuals

```{r}
model.fit <- lm(life_exp ~ population + murder + hs_grad + frost, data = state_no_11)

data_pred_res <- state_no_11 %>% 
  add_predictions(model.fit) %>% 
  add_residuals(model.fit)
```

ii) randomly resample the residuals (with replacement), leaving X and fitted value unchanged

```{r}
set.seed(1)
sample_res <- as.tibble(sample(data_pred_res$resid, nrow(data_pred_res), replace = TRUE))
new_data_pred_res <- cbind(data_pred_res, sample_res) %>% rename("resid_sample" = value)
```

iii) add new sampled residuals to fitted value

```{r}
new_data_pred_res <- new_data_pred_res %>% mutate(new_fitted = pred + resid_sample)
```

iv) regress new fitted value ("new" observations) with origianl predictors

```{r}
new_model_fit <- lm(new_fitted ~ population + murder + hs_grad + frost, data = new_data_pred_res)
anova(new_model_fit)["Residuals","Mean Sq"] # get the MSE
```


Put everything into function and repeat for 10 and 1000 times:

```{r write a function}
new_bootstrap <- function(model, n) {
  model_output <- vector("list", length = n)
  MSE_output <- vector("list", length = n)
  
  model.fit <- lm(life_exp ~ population + murder + hs_grad + frost, data = state_no_11)

  data_pred_res <- state_no_11 %>% add_predictions(model.fit) %>% add_residuals(model.fit)
    
  for (i in 1:n) {
    
    sample_res <- as.tibble(sample(data_pred_res$resid, nrow(data_pred_res), replace = TRUE))
    
    new_data_pred_res <- cbind(data_pred_res, sample_res) %>% rename("resid_sample" = value) %>%
      mutate(new_fitted = pred + resid_sample)
    
    new_model_fit <- lm(new_fitted ~ population + murder + hs_grad + frost, data = new_data_pred_res)
    
    model_output[[i]] <- new_model_fit
    MSE_output[i] <- anova(new_model_fit)["Residuals","Mean Sq"]
    
  }
   tibble(model_output,
          MSE_output = MSE_output %>% as.numeric())
}

```

repeat for 10 and 1000 times:

```{r}
set.seed(2)
newboot_10 <- new_bootstrap(model, 10)
newboot_1000 <- new_bootstrap(model, 1000)

summary(newboot_10$MSE_output)
summary(newboot_1000$MSE_output)

# compare previous 10 folds Cross validation method:
par(mfrow = c(1,3))
boxplot(model_caret$resample$RMSE, main = "MSE of 10 fold CV", ylim = c(0, 1.2))
boxplot(newboot_10$MSE_output, main = "MSE of 10 repeats", ylim = c(0, 1.2) )
boxplot(newboot_1000$MSE_output, main = "MSE of 1000 repeats", ylim = c(0, 1.2))
```

__Comment__: The new bootstrap method achieved a lower prediction MSE with less variance compared to cross validation method. This method relies on resampling residual errors and add to predicted value to create a new set of pseudo "new observations", then refit the model. We tested the predictive ability of the model after generating a new set of "observations" in each cycle. Here we can examine the mean value and variability of MSE. I would recommend the new boostrap method because it does not leave out any data from the full dataset. In addition, it is capable of generating "new" data point for us to test for our model predictibility. So I would say the second method is more reliable. 

